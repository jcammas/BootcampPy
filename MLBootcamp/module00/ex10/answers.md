### Why do we concatenate a column of ones to the left of the x vector when we use the linear algebra trick?

- ax + b => il faut tenir compte de la constante 'b' + ça permet de multiplier directement le vecteur avec x (opti + équilibre)

### Why does the loss function square the distances between the data points and their predicted values?

- avoir que des valeurs positives

### What does the cost function’s output represent?

- la perte engendrée lorsqu'on utilise notre model

### Toward which value do we want the loss function to tend? What would that mean?

- 0 => model parfait

### Do you understand why are matrix multiplications are not commutative?

- opération asymétrique, ordre de calcul à respecter
